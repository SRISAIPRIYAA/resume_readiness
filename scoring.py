
SKILL_SCORES = {
    "web development": {
    "html": 1.0, "html5": 1.0, "css": 1.0, "css3": 1.0, "javascript": 1.0,
    "js": 1.0, "typescript": 0.5, "react": 0.75, "reactjs": 0.75, "angular": 0.5,
    "vue": 0.5, "next.js": 0.5, "nuxt": 0.25, "node": 0.75, "node.js": 0.75,
    "express": 0.75, "django": 0.5, "flask": 0.5, "bootstrap": 0.5, "tailwind": 0.5,
    "jquery": 0.25, "php": 0.5, "laravel": 0.5, "spring": 0.5, "graphql": 0.5,
    "rest api": 0.75, "websocket": 0.5, "sass": 0.25, "scss": 0.25, "less": 0.25,
    "webpack": 0.25, "babel": 0.25, "eda": 0.25, "responsive design": 0.5,
    "web security": 0.5, "testing": 0.5, "unit testing": 0.5, "integration testing": 0.5,
    "seo": 0.5, "performance optimization": 0.5, "cross browser compatibility": 0.25,
    "web animation": 0.25, "ajax": 0.25, "json": 0.25, "api integration": 0.5,
    "progressive web app": 0.5, "web accessibility": 0.25, "cms": 0.25, "wordpress": 0.25,
    "drupal": 0.25, "joomla": 0.25, "web performance": 0.5, "frontend": 0.5, "backend": 0.5,
    # Additional skills to reach ~100
    "devops": 0.25, "seo optimization": 0.5, "website analytics": 0.25, "user experience": 0.5,
    "ui design": 0.5, "ux design": 0.5, "figma": 0.5, "adobe xd": 0.5, "photoshop": 0.25,
    "illustrator": 0.25, "canva": 0.25, "version control": 0.5, "git": 1.0, "github": 0.5,
    "bitbucket": 0.25, "docker": 0.5, "restful api": 0.75, "web app development": 0.75,
    "web frameworks": 0.5, "content management": 0.5, "website optimization": 0.5,
    "server management": 0.5, "hosting": 0.25, "domain management": 0.25, "cloud hosting": 0.5,
    "cdn": 0.25, "web sockets": 0.5, "graphql api": 0.5, "typescript react": 0.5,
    "responsive ui": 0.5, "accessibility compliance": 0.25, "w3c validation": 0.25,
    "interactive web": 0.5, "web animation css": 0.25, "single page app": 0.5,
    "progressive enhancement": 0.25, "web performance tuning": 0.5, "content strategy": 0.25,
    "copywriting": 0.25, "technical writing": 0.25, "teamwork": 0.25, "problem solving": 0.5,
    "project management": 0.5, "communication": 0.25, "agile": 0.5, "scrum": 0.5,
    "jira": 0.5, "trello": 0.25, "asana": 0.25, "slack": 0.25, "workflow automation": 0.25,
    "performance testing": 0.5, "load testing": 0.5, "security testing": 0.5, "cross platform": 0.5,
    "browser debugging": 0.5, "mobile first design": 0.5, "responsive layouts": 0.5,
    "seo tools": 0.25, "google analytics": 0.25, "adobe analytics": 0.25, "web trends": 0.25,
    "html semantics": 0.5, "css grid": 0.5, "flexbox": 0.5, "web components": 0.5,
    "custom themes": 0.25, "plugin development": 0.25, "ecommerce": 0.5, "shopify": 0.25,
    "magento": 0.25, "woocommerce": 0.25, "site speed optimization": 0.5, "caching": 0.25
},

    "devops": {
    "docker": 1.0, "docker-compose": 0.75, "kubernetes": 1.0, "k8s": 1.0,
    "jenkins": 0.75, "ansible": 0.5, "terraform": 0.5, "ci/cd": 1.0, "aws": 1.0,
    "amazon web services": 1.0, "azure": 0.75, "gcp": 0.75, "google cloud": 0.75,
    "linux administration": 0.5, "bash scripting": 0.5, "shell scripting": 0.5,
    "helm": 0.25, "git": 1.0, "gitlab": 0.5, "github": 0.5, "prometheus": 0.5,
    "grafana": 0.5, "nginx": 0.5, "apache": 0.5, "load balancing": 0.5,
    "monitoring": 0.5, "infrastructure as code": 0.75, "cloudformation": 0.5,
    "elastic stack": 0.25, "elk": 0.25, "kibana": 0.25, "eda": 0.25,
    "scripting automation": 0.5, "log analysis": 0.5, "container monitoring": 0.5,
    "system optimization": 0.5, "security compliance": 0.5, "continuous delivery": 0.75,
    "continuous integration": 0.75, "serverless": 0.5, "microservices": 0.5,
    "high availability": 0.5, "disaster recovery": 0.5, "scaling": 0.5,
    "alerting": 0.25, "backup automation": 0.25, "performance tuning": 0.5,
    "configuration management": 0.5, "deployment automation": 0.75, "cloud migration": 0.5,
    # Additional skills to reach ~100
    "ci tools": 0.5, "cd tools": 0.5, "spinnaker": 0.25, "circleci": 0.25, "travis ci": 0.25,
    "bitbucket pipelines": 0.25, "nagios": 0.25, "zabbix": 0.25, "new relic": 0.25,
    "app dynamics": 0.25, "splunk": 0.5, "logstash": 0.25, "fluentd": 0.25,
    "puppet": 0.25, "chef": 0.25, "saltstack": 0.25, "orchestration": 0.5,
    "deployment strategies": 0.5, "blue green deployment": 0.5, "canary deployment": 0.5,
    "rolling updates": 0.25, "infrastructure monitoring": 0.5, "alerts management": 0.25,
    "incident response": 0.5, "root cause analysis": 0.25, "system architecture": 0.5,
    "high scalability": 0.5, "load testing": 0.5, "stress testing": 0.25,
    "fault tolerance": 0.5, "continuous monitoring": 0.5, "application monitoring": 0.5,
    "network monitoring": 0.25, "cloud security": 0.5, "iam": 0.25, "access control": 0.25,
    "secret management": 0.25, "vault": 0.25, "hashicorp vault": 0.25, "aws lambda": 0.5,
    "azure functions": 0.25, "gcp cloud functions": 0.25, "event-driven architecture": 0.25,
    "observability": 0.5, "metrics collection": 0.5, "tracing": 0.25, "application logging": 0.25,
    "system logging": 0.25, "alert configuration": 0.25, "scaling automation": 0.5,
    "infrastructure cost optimization": 0.25, "resource provisioning": 0.5, "cloud architecting": 0.5,
    "hybrid cloud": 0.25, "multi-cloud": 0.25, "virtualization": 0.5, "vmware": 0.25,
    "hyper-v": 0.25, "ci/cd pipelines": 0.75, "automation scripts": 0.5, "team collaboration": 0.5,
    "communication": 0.25, "agile methodology": 0.5, "scrum": 0.5, "kanban": 0.25,
    "project management": 0.5, "problem solving": 0.5, "troubleshooting": 0.5, "documentation": 0.25
},

    "ai/ml": {
    "machine learning": 1.0, "ml": 1.0, "deep learning": 0.75, "dl": 0.75,
    "tensorflow": 0.75, "pytorch": 0.75, "scikit-learn": 0.75, "sklearn": 0.75,
    "keras": 0.5, "nlp": 0.5, "natural language processing": 0.5, "computer vision": 0.5,
    "opencv": 0.5, "reinforcement learning": 0.5, "rl": 0.5, "transformers": 0.5,
    "huggingface": 0.5, "llm": 0.5, "time series": 0.5, "feature engineering": 0.75,
    "xgboost": 0.5, "lightgbm": 0.5, "catboost": 0.5, "data preprocessing": 0.75,
    "data cleaning": 0.75, "eda": 0.5, "exploratory data analysis": 0.5,
    "model deployment": 0.5, "mlops": 0.5, "statistical modeling": 0.5,
    "bayesian methods": 0.25, "gradient boosting": 0.5, "random forest": 0.5,
    "svm": 0.25, "support vector machine": 0.25, "decision tree": 0.25,
    "logistic regression": 0.25, "classification": 0.5, "regression": 0.5,
    "clustering": 0.5, "k-means clustering": 0.25, "hierarchical clustering": 0.25,
    "dimensionality reduction": 0.25, "pca": 0.25, "lda": 0.25,
    "unsupervised learning": 0.5, "supervised learning": 0.5,
    "cnn": 0.25, "convolutional neural network": 0.25,
    "rnn": 0.25, "recurrent neural network": 0.25,
    "lstm": 0.25, "gru": 0.25, "gan": 0.25, "autoencoder": 0.25,
    "hyperparameter tuning": 0.5, "model selection": 0.5, "cross validation": 0.5,
    "train test split": 0.5, "feature selection": 0.5, "feature extraction": 0.5,
    "data augmentation": 0.5, "image processing": 0.5, "object detection": 0.5,
    "segmentation": 0.5, "speech recognition": 0.5, "text classification": 0.5,
    "sentiment analysis": 0.5, "word embeddings": 0.5, "glove": 0.25, "word2vec": 0.25,
    "fasttext": 0.25, "tokenization": 0.25, "pos tagging": 0.25, "named entity recognition": 0.25,
    "ner": 0.25, "sequence modeling": 0.25, "time series forecasting": 0.5,
    "arima": 0.25, "sarima": 0.25, "prophet": 0.25, "unsupervised feature learning": 0.25,
    "reinforcement agent": 0.25, "policy gradient": 0.25, "q-learning": 0.25,
    "deep q-network": 0.25, "reward function": 0.25, "ml pipeline": 0.5,
    "ensemble learning": 0.5, "bagging": 0.25, "boosting": 0.25, "stacking": 0.25,
    "model evaluation": 0.5, "accuracy": 0.25, "precision": 0.25, "recall": 0.25,
    "f1-score": 0.25, "roc auc": 0.25, "confusion matrix": 0.25, "feature importance": 0.5,
    "data visualization": 0.5, "matplotlib": 0.5, "seaborn": 0.5, "plotly": 0.25,
    "jupyter notebook": 0.5, "google colab": 0.25, "pipelines": 0.25, "scaling": 0.25,
    "normalization": 0.25, "standardization": 0.25, "cross entropy": 0.25, "loss functions": 0.25,
    "optimization algorithms": 0.5, "sgd": 0.25, "adam": 0.25, "rmsprop": 0.25
},
"data science": {
    "pandas": 1.0, "numpy": 1.0, "matplotlib": 0.75, "seaborn": 0.75, "sql": 1.0,
    "power bi": 0.5, "tableau": 0.5, "excel": 0.5, "data cleaning": 1.0,
    "data wrangling": 0.75, "data visualization": 0.75, "statistics": 0.5,
    "hypothesis testing": 0.5, "r programming": 0.25, "bigquery": 0.25,
    "spark": 0.5, "hadoop": 0.5, "etl": 0.75, "data pipeline": 0.5,
    "feature selection": 0.5, "regression": 0.5, "classification": 0.5,
    "clustering": 0.5, "k-means clustering": 0.25, "hierarchical clustering": 0.25,
    "dash": 0.25, "plotly": 0.25, "time series analysis": 0.5,
    "eda": 0.5, "exploratory data analysis": 0.5, "correlation analysis": 0.25,
    "data preprocessing": 0.75, "data modeling": 0.5, "data aggregation": 0.25,
    "descriptive statistics": 0.25, "inferential statistics": 0.25,
    "data reporting": 0.25, "business intelligence": 0.5, "dashboard creation": 0.5,
    "report automation": 0.25, "trend analysis": 0.25, "predictive analytics": 0.5,
    "sql analysis": 0.5, "kpi reporting": 0.25, "dataset handling": 0.5,
    "data cleaning techniques": 0.5, "data manipulation": 0.5,
    "data summarization": 0.5, "data insights": 0.5, "data storytelling": 0.25,
    "data transformation": 0.5, "feature engineering": 0.75, "normalization": 0.5,
    "standardization": 0.5, "data imputation": 0.5, "missing value handling": 0.5,
    "outlier detection": 0.5, "data augmentation": 0.5, "data integration": 0.5,
    "data extraction": 0.5, "data profiling": 0.25, "data cleaning automation": 0.25,
    "data pipelines": 0.5, "data ingestion": 0.5, "data lakes": 0.25, "data warehousing": 0.5,
    "big data": 0.5, "distributed computing": 0.25, "cloud analytics": 0.25,
    "ml integration": 0.5, "data preprocessing pipelines": 0.5, "sql queries": 0.5,
    "joins": 0.5, "group by": 0.25, "aggregate functions": 0.25, "data summarization techniques": 0.25,
    "dimensionality reduction": 0.25, "pca": 0.25, "lda": 0.25, "correlation coefficient": 0.25,
    "anova": 0.25, "chi square test": 0.25, "data modeling techniques": 0.5, "feature scaling": 0.5,
    "one-hot encoding": 0.5, "label encoding": 0.5, "binning": 0.25, "cross validation": 0.5,
    "train test split": 0.5, "model evaluation": 0.5, "accuracy": 0.25, "precision": 0.25,
    "recall": 0.25, "f1 score": 0.25, "roc auc": 0.25, "confusion matrix": 0.25,
    "regression analysis": 0.5, "linear regression": 0.25, "logistic regression": 0.25,
    "decision trees": 0.25, "random forest": 0.5, "gradient boosting": 0.5,
    "xgboost": 0.5, "lightgbm": 0.5, "catboost": 0.5, "neural networks": 0.5,
    "cnn": 0.25, "rnn": 0.25, "lstm": 0.25, "gan": 0.25, "autoencoder": 0.25,
    "time series forecasting": 0.5, "arima": 0.25, "sarima": 0.25, "prophet": 0.25,
    "anova testing": 0.25, "eda tools": 0.25, "data storytelling tools": 0.25
},

    "cybersecurity": {
    "penetration testing": 1.0, "ethical hacking": 1.0, "network security": 0.75,
    "cryptography": 0.75, "vulnerability assessment": 0.5, "firewall configuration": 0.5,
    "wireshark": 0.5, "nmap": 0.5, "burp suite": 0.5, "metasploit": 0.5,
    "intrusion detection": 0.5, "incident response": 0.5, "malware analysis": 0.5,
    "security operations": 0.5, "siem": 0.5, "kali linux": 0.5, "threat hunting": 0.5,
    "risk assessment": 0.25, "web application security": 0.5, "forensics": 0.25,
    "cloud security": 0.5, "identity and access management": 0.5, "zero trust": 0.25,
    "public key infrastructure": 0.25, "tls": 0.25, "ssl": 0.25, "eda": 0.25,
    "security compliance": 0.5, "penetration test automation": 0.5,
    "incident reporting": 0.25, "security auditing": 0.5, "security monitoring": 0.5,
    "security assessment": 0.5, "penetration testing lab": 0.25,
    "ethical hacking lab": 0.25, "cyber defense": 0.5, "cyber risk": 0.25,
    "firewall management": 0.25, "endpoint security": 0.5, "network monitoring": 0.5,
    "vulnerability scanning": 0.5, "incident simulation": 0.25, "security policy": 0.25,
    "threat modeling": 0.25, "security tools": 0.25, "penetration tools": 0.25,
    "digital forensics": 0.25, "malware reverse engineering": 0.25,
    # Additional skills for messy resumes / synonyms / tools
    "cyber threat intelligence": 0.5, "social engineering": 0.5, "phishing analysis": 0.5,
    "ethical hacking certification": 0.25, "oscp": 0.25, "ceh": 0.25, "compTIA security+": 0.25,
    "information security": 0.75, "it security": 0.75, "cyber security": 0.75,
    "penetration tests": 0.5, "ethical hacker": 0.5, "red team": 0.5, "blue team": 0.5,
    "purple team": 0.25, "network penetration": 0.5, "system hardening": 0.25,
    "application security": 0.5, "cloud penetration testing": 0.5, "siem tools": 0.5,
    "security operations center": 0.5, "soc": 0.5, "cybersecurity analysis": 0.5,
    "security management": 0.5, "incident management": 0.5, "cyber risk assessment": 0.25,
    "threat intelligence": 0.5, "vulnerability management": 0.5, "malware detection": 0.5,
    "penetration methodology": 0.25, "ethical hacking methodology": 0.25,
    "information assurance": 0.25, "security frameworks": 0.25, "nist": 0.25,
    "iso 27001": 0.25, "cobit": 0.25, "it governance": 0.25, "risk mitigation": 0.5,
    "compliance audit": 0.25, "cybersecurity tools": 0.25, "vulnerability assessment tools": 0.25,
    "cyber defense strategies": 0.25, "penetration testing tools": 0.25, "malware forensics": 0.25,
    "reverse engineering": 0.25, "security monitoring tools": 0.25, "network defense": 0.5,
    "intrusion prevention": 0.5, "firewall rules": 0.25, "security operations management": 0.25,
    "endpoint protection": 0.5, "antivirus management": 0.25, "patch management": 0.25,
    "vulnerability patching": 0.25, "security incident handling": 0.25, "threat analysis": 0.5
}
}

PREMIUM_CERTS = [
    'google', 'aws', 'microsoft', 'azure', 'cisco', 'oracle', 'pmp', 'scrum master',
    'cissp', 'ceh', 'oscp', 'vmware', 'red hat', 'ibm data science', 'ibm ai',
    'aws certified solutions architect', 'aws certified developer', 'aws certified sysops',
    'microsoft azure fundamentals', 'microsoft azure administrator', 'google cloud professional',
    'google cloud architect', 'google cloud data engineer', 'salesforce', 'sap',
    'tableau certified', 'power bi certified', 'hadoop', 'cloudera', 'databricks',
    'kaggle grandmaster', 'datacamp expert', 'tensorflow developer', 'pytorch expert',
    'compTIA security+', 'compTIA network+', 'linux foundation', 'docker certified',
    'kubernetes certified', 'jenkins certified', 'redhat certified engineer',
    'redhat certified architect', 'aws machine learning specialty', 'azure AI engineer',
    'cisco certified network professional', 'oracle cloud certified', 'oracle DBA',
    'project management professional', 'lean six sigma', 'itil', 'penetration testing professional',
    'ethical hacking', 'cybersecurity analyst', 'big data professional', 'ai engineer',
    'deep learning specialization', 'nlp specialization', 'data engineering', 'devops professional',
    'solution architect', 'cloud architect', 'blockchain developer', 'full stack developer',
    'software testing professional', 'agile certified practitioner', 'business analyst professional',
    'machine learning engineer', 'data science professional', 'azure solutions architect', 'google professional data engineer',
    'oracle database administrator', 'sap hana consultant', 'information security manager', 'network security expert', 'iitm', 'iit'
]

MAJOR_ACHIEVEMENTS = [
    'sih', 'smart india hackathon', 'google code jam', 'facebook hacker cup',
    'microsoft imagine cup', 'codeforces global round winner', 'icpc world finals',
    'topcoder open finals', 'kaggle competitions grandmaster', 'google kickstart winner',
    'international math olympiad medalist', 'international informatics olympiad medalist',
    'national coding competition winner', 'national science fair winner',
    'first prize ieee project', 'first prize nss project', 'national innovation award',
    'international robotics competition winner', 'international hackathon winner',
    'ieee hackathon champion', 'acm icpc regional winner', 'top 3 google challenge',
    'national techfest winner', 'research paper accepted in reputed journal',
    'patent granted', 'innovation award', 'national startup challenge winner',
    'international startup competition winner', 'global entrepreneurship award',
    'technology excellence award', 'best research project award', 'young scientist award',
    'national coding olympiad winner', 'international coding olympiad winner',
    'global ai challenge winner', 'national hackathon winner', 'cybersecurity challenge winner',
    'robotics innovation award', 'best machine learning project', 'outstanding contribution award',
    'software innovation award'
]

SKILL_MAPPING = {"html/css": "html", "leadership": "leadership", "event": "event", "management": "management", "teamwork": "teamwork"}

FEATURE_NAMES = [
    "CGPA", "Skill_Score", "Cert_Score", "Project_Score", "Internship_Score",
    "Achievement_Score", "Selected",
    "Internship_Domain_AI/ML", "Internship_Domain_Cybersecurity",
    "Internship_Domain_Data Science", "Internship_Domain_DevOps",
    "Internship_Domain_Web Dev"
]

DOMAIN_LIST = ["Internship_Domain_AI/ML", "Internship_Domain_Cybersecurity", "Internship_Domain_Data Science", "Internship_Domain_DevOps", "Internship_Domain_Web Dev"]

import os
import pandas as pd
from joblib import load
from extract_resume_gemini import extract_resume

# ----------------- Constants -----------------
DOMAIN_LIST = [
    "Internship_Domain_AI/ML",
    "Internship_Domain_Cybersecurity",
    "Internship_Domain_Data Science",
    "Internship_Domain_DevOps",
    "Internship_Domain_Web Dev"
]


scor = None  # Global variable to hold detailed scores

# ----------------- Helper functions -----------------
def one_hot_encode_domain(domain):
    domain_lower = domain.lower()
    encoding = []
    for d in DOMAIN_LIST:
        col_lower = d.lower().replace("internship_domain_", "")
        encoding.append(1 if domain_lower == col_lower else 0)
    return encoding

def score_cgpa(resume_data):
    try:
        cgpa = float(resume_data.get("cgpa", 0))
    except ValueError:
        cgpa = 0
    return min((cgpa / 10) * 5, 5)

def score_skills(resume_data, domain):
    resume_skills = [s.lower().strip() for s in resume_data.get("skills", [])]
    domain_skills = SKILL_SCORES.get(domain.lower(), {})
    score = 0
    for skill in resume_skills:
        skill = SKILL_MAPPING.get(skill, skill)
        for ds_skill in domain_skills:
            if ds_skill in skill:
                score += domain_skills[ds_skill]
                break
    return min(score, 5)

def score_certs(resume_data):
    certifications = resume_data.get("certs", [])
    score = 0
    for cert in certifications:
        cert_lower = cert.lower()
        if any(pc in cert_lower for pc in PREMIUM_CERTS):
            score += 2
        else:
            score += 0.5
    return min(score, 5)

def score_projects(resume_data, domain):
    projects = resume_data.get("projects", [])
    domain_skills = SKILL_SCORES.get(domain.lower(), {})
    score = 0
    for project in projects:
        combined_text = " ".join(str(value) for value in project.values()).lower()
        if any(skill in combined_text for skill in domain_skills):
            score += 2
        else:
            score += 1
    return min(score, 5)

def score_internships(resume_data, domain):
    internships = resume_data.get("internships", [])
    domain_skills = SKILL_SCORES.get(domain.lower(), {})
    score = 1.5
    for intern in internships:
        text = " ".join(str(v) for v in intern.values()).lower()
        if any(skill in text for skill in domain_skills):
            score += 1.5
        else:
            score += 1
    return min(score, 5)

def score_achievements(resume_data):
    achievements = resume_data.get("achievements", [])
    score = 0
    for ach in achievements:
        text = " ".join(str(v) for v in ach.values()).lower()
        if any(ma in text for ma in MAJOR_ACHIEVEMENTS):
            score = 5
            break
        else:
            score += 1
    return min(score, 5)

def calculate_resume_score(resume_data, domain):
    return {
        "cgpa": score_cgpa(resume_data),
        "skills": score_skills(resume_data, domain),
        "certifications": score_certs(resume_data),
        "projects": score_projects(resume_data, domain),
        "internships": score_internships(resume_data, domain),
        "achievements": score_achievements(resume_data)
    }

# ----------------- Feature preparation -----------------
def load_model():
    return load("internship_success_model.joblib")

def prepare_features(resume_data, domain):
    global scor
    scores = calculate_resume_score(resume_data, domain)
    scor = scores
    domain_vector = one_hot_encode_domain(domain)
    feature_vector = [
        scores["cgpa"], scores["skills"], scores["certifications"],
        scores["projects"], scores["internships"], scores["achievements"]
    ] + domain_vector
    feature_columns = FEATURE_NAMES[:6] + FEATURE_NAMES[7:]
    return pd.DataFrame([feature_vector], columns=feature_columns)

# ----------------- Main scoring function -----------------
def score_resume(file_path, domain, api_key=None, model_name="gpt-4.1-mini"):
    # Load ML model
    model = load_model()
    
    # Extract structured resume data using extract_resume
    parsed_data = extract_resume(file_path, api_key=api_key, model_name=model_name)
    
    # Prepare features for the ML model
    features = prepare_features(parsed_data, domain)
    
    # Predict using the ML model
    prediction = model.predict(features)
    probability = model.predict_proba(features)[0][1] * 100 if hasattr(model, "predict_proba") else float(prediction[0]) * 100
    
    return {
        "scores": scor,
        "prediction": int(prediction[0]),
        "probability": round(probability, 2),
        "analyzed_data": parsed_data
    }

# ----------------- Example usage -----------------
if __name__ == "__main__":
    result = score_resume("resume.pdf", "data science", api_key=os.getenv("OPENAI_API_KEY"))
    print(result)
